


Diederick's testing code. Save it under `tests/python/11.py`.
```py
import os
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["OPENBLAS_NUM_THREADS"] = "1"
import numpy as np
import ioh
from itertools import product
from functools import partial
from multiprocessing import Pool, cpu_count

import sys
import argparse
import warnings

import time

rootname = "./doit"

from dataclasses import dataclass


import abc
from typing import Tuple


SolutionType = Tuple[float, np.ndarray]

DEFAULT_MAX_BUDGET = 10_000
SIGMA_MAX = 1e3


class Algorithm(abc.ABC):
    budget: int = DEFAULT_MAX_BUDGET

    @abc.abstractmethod
    def __call__(self, problem: ioh.ProblemType) -> SolutionType:
        pass

    def should_terminate(self, problem: ioh.ProblemType, n_evals: int = 0) -> bool:
        return (
            problem.state.optimum_found
            or (problem.state.evaluations + n_evals) > self.budget
        )


@dataclass
class GeneticAlgorithm(Algorithm):
    budget: int = DEFAULT_MAX_BUDGET
    n_parents: int = 2
    n_offspring: int = 100
    plus_selection: bool = False
    p_mutation: float = None
    verbose: bool = False
    maximize: bool = False
    p_crossover: float = 0
    dynamic_frequency: int = 1
    min_mutation_flip: int = 1
    rank_based: bool = False
    starting_distance: float = 0
    mut_after_cross: bool = True

    def __call__(self, problem: ioh.problem.IntegerSingleObjective) -> SolutionType:
        dim = problem.meta_data.n_variables

        fitness_func = problem
        self.ub = problem.bounds.ub[0]

        p = np.ones(dim) / dim

        pm = self.p_mutation
        pc = self.p_crossover or 0
        # Initialize population
        if self.starting_distance > 0:
            parents = np.repeat(np.atleast_2d(problem.optimum.x),self.n_parents, axis=0)
            mask = np.random.uniform(size=(self.n_parents, dim)) < self.starting_distance
            parents = np.bitwise_xor(parents, mask)
        else:
            parents = np.random.choice([0, 1], size=(self.n_parents, dim))
        offspring = np.empty((self.n_offspring, dim), dtype=int)

        if not self.rank_based:
            fitness = np.array([fitness_func(x) for x in parents])
            offspring_fitness = np.empty(self.n_offspring)

        gen_idx = 1
        while not self.should_terminate(problem, self.n_offspring):
            update_fitness = (gen_idx % self.dynamic_frequency) == 0
            gen_idx += 1
            # Select n_parents parents (Rank selection)
            # idx = fitness_order
            if update_fitness:
                fitness_func.step()

            if self.rank_based:
                parents = np.array(problem.rank(parents))[: self.n_parents]
            else:
                idx = np.argsort(fitness)
                if self.maximize:
                    idx = idx[::-1]
                idx = idx[: self.n_parents]
                fitness = fitness[idx]
                parents = parents[idx, :]


            # Recombine lambda offspring (1-point crossover)
            pidx = np.random.choice(range(self.n_parents), size=self.n_offspring * 2)

            for i, (p1, p2) in enumerate(zip(pidx[::2], pidx[1::2])):
                crossed = False
                if np.random.uniform() < pc:
                    mask = np.random.randint(0, 2, size=dim)
                    offspring[i] = (parents[p1] * mask) + (parents[p2] * np.abs(1 - mask))
                    crossed = True
                else:
                    offspring[i] = parents[p1]

                if (not crossed) or self.mut_after_cross:
                # n_mutate offspring (bit-flip n_mutation)
                    n = max(np.random.binomial(dim, pm), self.min_mutation_flip)
                    idx = np.random.choice(dim, n, False, p=p)
                    offspring[i, idx] = np.abs(1 - offspring[i, idx])

                if not self.rank_based:
                    offspring_fitness[i] = fitness_func(offspring[i])

            if self.plus_selection:
                if not self.rank_based:
                    if update_fitness:
                        pfitness_new = [fitness_func(x) for x in parents]
                        fitness = np.r_[pfitness_new, offspring_fitness]
                    else:
                        fitness = np.r_[fitness, offspring_fitness]
                parents = np.vstack([parents, offspring])
            else:
                parents = offspring
                if not self.rank_based:
                    fitness = offspring_fitness

            # fitness_order = np.argsort(problem.rank_indices(parents))
                # fitness = offspring_fitness

            if problem.state.optimum_found:
                break

        return problem.state.current_best.y, problem.state.current_best.x

def runParallelFunction(runFunction, arguments):
    """
        Return the output of runFunction for each set of arguments,
        making use of as much parallelization as possible on this system

        :param runFunction: The function that can be executed in parallel
        :param arguments:   List of tuples, where each tuple are the arguments
                            to pass to the function
        :return:
    """


    arguments = list(arguments)
    p = Pool(min(200, len(arguments)))
    results = p.map(runFunction, arguments)
    p.close()
    return results



def run_optimizer(temp, rootname, functions):
    print(temp)
    n_offspring, n_parents, selection_plus, pmbase, pc, dynamic_frequency, min_mutation_flip, dim, starting_distance, budget_factor, mut_after_cross = temp
    if n_parents > n_offspring and not selection_plus:
        return
    filename = f"ga_{n_offspring}_{n_parents}_{pmbase:.1f}_{pc}_{mut_after_cross}_{selection_plus}_{min_mutation_flip}_{dynamic_frequency}_{starting_distance}_{dim}"
    # if min_mutation_flip != 1:
    #     filename = f"ga_{n_offspring}_{n_parents}_{pmbase}_{pc}_{selection_plus}_{min_mutation_flip}"
    if os.path.isdir(f'{rootname}/{filename}'):
        return
    logger = ioh.logger.Analyzer(root = f'{rootname}',
                                 folder_name = filename,
                                 algorithm_name=f'GA')
    logger.set_experiment_attributes({'n_offspring' : f"{n_offspring}",
                                      'n_parents' : f"{n_parents}",
                                      'p_mutation' : f"{pmbase:.1f}",
                                      'p_crossover' : f"{pc}",
                                      'selection_plus' : f"{selection_plus}",
                                      'dynamic_frequency' : f"{dynamic_frequency}",
                                     'min_mutation_flip' : f"{min_mutation_flip}",
                                     'starting_distance' : f"{starting_distance}",
                                     'mut_after_cross' : f"{mut_after_cross}",
                                     'budget_factor' : f"{budget_factor}"})
    dbv1 = ioh.problem.DynamicBinValPareto
    dbv2 = ioh.problem.DynamicBinValPowersOfTwo
    dbv3 = ioh.problem.DynamicBinValUniform
    fcts = []
    if 10001 in functions:
        fcts.append(dbv3)
    if 10002 in functions:
        fcts.append(dbv2)
    if 10003 in functions:
        fcts.append(dbv1)

    for func in fcts:
        pm = pmbase / dim
        ga = GeneticAlgorithm(maximize=True, n_offspring=n_offspring, n_parents=n_parents, p_crossover=pc, p_mutation=pm, budget=budget_factor*dim, dynamic_frequency=dynamic_frequency, plus_selection=selection_plus, rank_based = False, starting_distance=starting_distance, min_mutation_flip=min_mutation_flip, mut_after_cross = mut_after_cross)
        for iid in range(15):
            f_instance = func(int(iid), dim)
            f_instance.attach_logger(logger)
            for _ in range(1):
                try:
                    ga(f_instance)
                except:
                    print("Failure?")
                f_instance.reset()

    if 10004 in functions:
        func = ioh.problem.DynamicBinValRanking

        pm = pmbase / dim
        ga = GeneticAlgorithm(maximize=True, n_offspring=n_offspring, n_parents=n_parents, p_crossover=pc, p_mutation=pm, budget=budget_factor*dim, dynamic_frequency=dynamic_frequency, plus_selection=selection_plus, rank_based=True, starting_distance=starting_distance, min_mutation_flip=min_mutation_flip, mut_after_cross = mut_after_cross)
        for iid in range(15):
            f_instance = func(int(iid), dim)
            f_instance.attach_logger(logger)
            for _ in range(1):
                try:
                    ga(f_instance)
                except:
                    print("Failure?")
                f_instance.reset()



    logger.close()


def experiment_full():
    pm = [1, 2, 5]
    n_offspring = [1,2,10,100]
    n_parents = [1,2,10,100]
    selection_plus = [False, True]
    pc = [0,0.9]
    dynamic_frequency = [1, 1_000_000]
    min_mutation_flip = [1]
    args = product(n_offspring, n_parents, selection_plus, pm, pc, dynamic_frequency, min_mutation_flip)

    # return args
    return list(args)

def experiment_1plusmu():
    pm = [1, 2, 5]
    n_offspring = [1,2,10,100]
    n_parents = [1]
    selection_plus = [True]
    pc = [0,0.9]
    dynamic_frequency = [1]
    min_mutation_flip = [1]
    args = product(n_offspring, n_parents, selection_plus, pm, pc, dynamic_frequency, min_mutation_flip)
    return list(args)

def experiment_crossover():
    pm = [1]
    n_offspring = [1]
    n_parents = [1]
    selection_plus = [False, True]
    pc = [0,0.1,0.25,0.5,0.75,0.9,1]
    dynamic_frequency = [1]
    min_mutation_flip = [1]

    args = product(n_offspring, n_parents, selection_plus, pm, pc, dynamic_frequency, min_mutation_flip)
    return list(args)

def experiment_lambda1():
    pm = [0,1, 2, 5]
    n_offspring = [1,2,10,100]
    n_parents = [1,2,10,100]
    selection_plus = [False, True]
    pc = [0,0.9]
    dynamic_frequency = [1, 1_000_000]
    min_mutation_flip = [0,1]

    args = product(n_offspring, n_parents, selection_plus, pm, pc, dynamic_frequency, min_mutation_flip)
    return list(args)

def exp_question1():
    pm = np.arange(0.3, 4.01, 0.1)
    n_offspring = [1,2,4,8]
    n_parents = [1]
    selection_plus = [True]
    pc = [0]
    dynamic_frequency = [1]
    min_mutation_flip = [0,1]
    dim = [1000]
    starting_distance = [0]

    args = product(n_offspring, n_parents, selection_plus, pm, pc, dynamic_frequency, min_mutation_flip, dim, starting_distance)
    return list(args)

def exp_question2():
    pm = np.arange(0.5, 4, 0.1)
    n_offspring = [1]
    n_parents = [1,2,4,8,16]
    selection_plus = [True]
    pc = [0, 0.5, 0.9]
    dynamic_frequency = [1]
    min_mutation_flip = [0]
    dim = [1000]
    starting_distance = [0.02, 0.05, 0]

    args = product(n_offspring, n_parents, selection_plus, pm, pc, dynamic_frequency, min_mutation_flip, dim, starting_distance)
    return list(args)

def exp_question3():
    pm = np.arange(0.7, 2, 0.1)
    n_offspring = [1]
    n_parents = [1,2,4,8,16,32,64,128]
    selection_plus = [True]
    pc = [0,0.9]
    dynamic_frequency = [1,10,25,50,100,250,500,1000]
    min_mutation_flip = [0]
    dim = [1000]
    starting_distance = [0]

    args = product(n_offspring, n_parents, selection_plus, pm, pc, dynamic_frequency, min_mutation_flip, dim, starting_distance)
    return list(args)

def exp_question11():
    pm = np.arange(0, 6.01, 0.1)
    n_offspring = [1]
    n_parents = [1]
    selection_plus = [True]
    pc = [0]
    mut_after_cross = [True]
    dynamic_frequency = [1]
    min_mutation_flip = [0,1]
    dim = [1000]
    budget_factor = [1000]
    starting_distance = [0]
    # funcs = [10001, 10002, 10003, 10004]

    args = product(n_offspring, n_parents, selection_plus, pm, pc, dynamic_frequency, min_mutation_flip, dim, starting_distance, budget_factor, mut_after_cross)#, funcs)
    return list(args)

def exp_question22():
    pm = np.arange(0.5, 4, 0.1)
    n_offspring = [1]
    n_parents = [1,2,3,4,8,16]
    selection_plus = [True]
    pc = [0, 0.5, 0.9]
    mut_after_cross = [True, False]
    dynamic_frequency = [1]
    min_mutation_flip = [0]
    dim = [1000]
    starting_distance = [0.02, 0.05, 0]
    budget_factor = [1000]
    # funcs = [10001, 10004]

    args = product(n_offspring, n_parents, selection_plus, pm, pc, dynamic_frequency, min_mutation_flip, dim, starting_distance, budget_factor, mut_after_cross)#, funcs)
    return list(args)

def exp_question33():
    pm = np.arange(0.7, 2, 0.1)
    n_offspring = [1]
    n_parents = [1,2,4,5,8,10,16,32]
    selection_plus = [True]
    pc = [0,0.9]
    mut_after_cross = [True, False]
    dynamic_frequency = [1,10,25,50,100,250,500,1000, 2000, 5000]
    min_mutation_flip = [0]
    dim = [1000]
    starting_distance = [0]
    budget_factor = [1000]
    # funcs = [10001, 10004]
    args = product(n_offspring, n_parents, selection_plus, pm, pc, dynamic_frequency, min_mutation_flip, dim, starting_distance, budget_factor, mut_after_cross)#, funcs)
    return list(args)

def exp_question44():
    pm = [0.5,1,1.5,2,3]
    n_offspring = [1,2,4,8]
    n_parents = [1,2,4,8,16,32]
    selection_plus = [True, False]
    pc = [0,0.5,0.9]
    mut_after_cross = [True, False]
    dynamic_frequency = [1, 1000000]
    min_mutation_flip = [0,1]
    dim = [1000]
    starting_distance = [0]
    budget_factor = [100]
    # funcs = [10001, 10004]
    args = product(n_offspring, n_parents, selection_plus, pm, pc, dynamic_frequency, min_mutation_flip, dim, starting_distance, budget_factor, mut_after_cross)#, funcs)
    return list(args)



if __name__ == '__main__':
    warnings.filterwarnings("ignore", category=RuntimeWarning)
    warnings.filterwarnings("ignore", category=FutureWarning)

    args = exp_question44()
    opt_runner = partial(run_optimizer, rootname = "./doit", functions=[10001,10002,10003,10004])
    runParallelFunction(opt_runner, args[:1])
```




```cpp
has_external_improved // Before February 2024
has_internal_improved || has_external_improved // In February 2024
has_internal_improved // In April 2024
```


Logging code.
```cpp
#define LOG_FILE_NAME "test.log"

#define LOG(message)                                                           \
  do {                                                                         \
    std::ofstream debug_log(LOG_FILE_NAME, std::ios::app);                     \
    auto now = std::chrono::system_clock::now();                               \
    std::time_t now_time = std::chrono::system_clock::to_time_t(now);          \
    debug_log << "["                                                           \
              << std::put_time(std::localtime(&now_time), "%Y-%m-%d %H:%M:%S") \
              << "] " << message << std::endl;                                 \
    debug_log.close();                                                         \
  } while (0)
```


Reproduce an experiment, where the JSON key 'best' records a higher value than expected.
```sh
cd $HOME/code/IOHexperimenter
./.BUILD_PYTHON
conda activate ./.conda_environment/
cd tests/python/
rm -rf doit/
python 11.py
```




You might get this error message:
```sh
CMake Error at CMakeLists.txt:52 (add_subdirectory):
  The source directory

    /home/dimitri/Selbstgemachte_Software/IOHexperimenter/external/fmt

  does not contain a CMakeLists.txt file.
```

In this case, run:
```sh
git submodule
git submodule init
git submodule update
```

In fact, the first, of the three commands above, will give:
```sh
-32e70c1b3454a9411de2ae8d23020e08f5381f11 external/MkLandscape
-1dcb44e79a17e703e024594487b3a442d87e4741 external/cxxopts
-7df30f91aee5444a733cec0b911d21cebdeb62ae external/fmt
-6a7ed316a5cdc07b6d26362c90770787513822d4 external/googletest
-bc889afb4c5bf1c0d8ee29ef35eaaf4c8bef8a5d external/json
-80dc998efced8ceb2be59756668a7e90e8bef917 external/pybind11
```

```sh
# parentheses only work in the fish shell
sudo chown -R (id -un):(id -gn) /home/dimitri/Selbstgemachte_Software/IOHexperimenter/
sudo chmod -R 700 /home/dimitri/Selbstgemachte_Software/IOHexperimenter/
```

```sh
git clone git@github.com:Habimm/IOHexperimenter.git
git submodule
git submodule init
git submodule update
sudo chown -R (id -un):(id -gn) /home/dimitri/Selbstgemachte_Software/IOHexperimenter/
sudo chmod -R 700 /home/dimitri/Selbstgemachte_Software/IOHexperimenter/
mkdir build
cd build
cmake -DCMAKE_INSTALL_PREFIX=./IOHexperimenter_headers ..
cd ..
sudo make install
```

To search for files under the current directory tree with a specific content:
```sh
grep -r "local_ioh"
```

To search for files under the current directory tree with a specific filename:
```sh
find . -iname "*local_ioh*"
```

To compile a file that uses the IOHexperimenter problems:
```sh
g++ -std=c++17 -I../external/fmt/include -I../include -o one_max one_max.cpp
```

```sh
set project_root /home/dimitri/code/IOHexperimenter
set fmt_include_path $project_root/external/fmt/include
set ioh_include_path $project_root/include

g++ -o one_max -g -std=c++17 -I$fmt_include_path -I$ioh_include_path one_max.cpp
./one_max
```

```sh
g++ -o one_max -g -std=c++17 -I$fmt_include_path -I$ioh_include_path one_max.cpp; and ./one_max
```

g++ version
```sh
g++ 9.4.0
```

Build everything:
```sh
git clone git@github.com:Habimm/IOHexperimenter.git
cd IOHexperimenter
git submodule
git submodule init
git submodule update
mkdir build
cd build
cmake -DCMAKE_INSTALL_PREFIX=./IOHexperimenter_headers ..
cd ..
sudo make install
```

Single Objective Bound Constrained Benchmark
CEC functions
definitions
pdf
```sh
https://github.com/P-N-Suganthan/2022-SO-BO
```

Prompt for writing CEC functions
```sh
void levy_func (double *x, double *f, int nx, double *Os,double *Mr, int s_flag, int r_flag) /* Levy */
{
    int i;
  f[0] = 0.0;
  sr_func (x, z, nx, Os, Mr,1.0, s_flag, r_flag); /* shift and rotate */

  double *w;
  w=(double *)malloc(sizeof(double)  *  nx);

  double sum1= 0.0;
  for (i=0; i<nx; i++)
  {
     w[i] = 1.0 + (z[i] - 0.0)/4.0;
  }

  double term1 = pow((sin(PI*w[0])),2);
  double term3 = pow((w[nx-1]-1),2) * (1+pow((sin(2*PI*w[nx-1])),2));

  double sum = 0.0;

  for (i=0; i<nx-1; i++)
  {
    double wi = w[i];
        double newv = pow((wi-1),2) * (1+10*pow((sin(PI*wi+1)),2));
    sum = sum + newv;
  }

  f[0] = term1 + sum + term3;// - 1.442600987052770; // - 1.442600987052770
  free(w);   // ADD THIS LINE to free memory! Thanks for Dr. Janez
}
rewrite this in the style of this:
        double evaluate(const std::vector<double> &x) override
        {
            auto sum1 = 0.0, sum2 = 0.0;
            for (const auto xi : x)
            {
                sum1 += cos(2.0 * IOH_PI * xi);
                sum2 += xi * xi;
            }
            if (std::isinf(sum2)) { return sum2; }

            auto result = 10.0 * (static_cast<double>(x.size()) - sum1) + sum2;
            std::cout << "result: " << result << std::endl;

            return result;
        }
ignore sr_func, further down the line replace z with x, the f will be returned as a double rather than its memory changed with a pointer
```

lint C++-17 code
```sh
# put the .clang-format file in the same directory
clang-format -i -style=llvm functions.hpp
```

Test Python bindings
```sh
conda activate ./.conda_environment
pip install -e .
ipython3
from ioh import problem
help(problem)
```

```sh
sudo apt install doxygen

conda activate ./.conda_environment
pip install breathe xmltodict sphinx sphinx-automodapi furo

cd /home/dimitri/code/IOHexperimenter/build
cmake -DBUILD_DOCS=ON ..
make doc
cd ..
ipython3 doc/generate_docs.py
```

```sh
true
git clone git@github.com-Habimm:Habimm/IOHexperimenter.git
cd IOHexperimenter
and git submodule
and git submodule init
and git submodule update
and . INSTALL
and conda activate ./.conda_environment
and pip install .
and cd ~
and ipython3 /home/dimitri/code/IOHexperimenter/tests/python/test_cec_functions.py
```

On a freshly cloned repo:
```sh
Step 1: Clone repo.
Step 2: Update git submodules.
Step 3: Install virtual environment.
Step 4: Install ioh package.
Step 5: Create .env file with a path to the static/ folder.
Step 6: Source .env.
Step 7: Run Python script.
```

```sh
echo "IOH_RESOURCES=/home/dimitri/code/IOHexperimenter/static" > .env
for line in (cat .env)
  set -x (echo $line | cut -d '=' -f 1) (echo $line | cut -d '=' -f 2-)
end
```

```sh
true
and git clone git@github.com-Habimm:Habimm/IOHexperimenter.git
and cd IOHexperimenter
and git submodule
and git submodule init
and git submodule update
and ./INSTALL_IOH
ln -fs (pwd)/static/cec_transformations build/tests/input_data
and echo "IOH_RESOURCES=/home/dimitri/code/IOHexperimenter/static" > .env
and ./RUN
```

```sh
./INSTALL_IOH
ln -fs (pwd)/static/cec_transformations build/tests/input_data
./RUN
```

In GitHub Actions we have the following useful environment variables:
```sh
GITHUB_WORKSPACE=/home/runner/work/IOHexperimenter/IOHexperimenter
RUNNER_WORKSPACE=/Users/runner/work/IOHexperimenter
```



```sh
sudo apt install doxygen

conda activate ./.conda_environment
pip install breathe xmltodict sphinx sphinx-automodapi furo

cd /home/dimitri/code/IOHexperimenter/build

cmake -DBUILD_DOCS=ON ..

wine "/home/dimitri/.wine/drive_c/Program Files/CMake/bin/cmake.exe" -DBUILD_DOCS=ON ..
make doc
cd ..
ipython3 doc/generate_docs.py
```




Build everything:
```sh
git clone git@github.com:Habimm/IOHexperimenter.git
cd IOHexperimenter
git submodule
git submodule init
git submodule update
mkdir build
cd build

cmake -DCMAKE_INSTALL_PREFIX=./IOHexperimenter_headers ..

wine "/home/dimitri/.wine/drive_c/Program Files/CMake/bin/cmake.exe" -DBUILD_DOCS=ON ..

wine "/home/dimitri/.wine/drive_c/Program Files/CMake/bin/cmake.exe" -DCMAKE_TOOLCHAIN_FILE=/home/dimitri/code/IOHexperimenter/mingw-w64-toolchain.cmake -DBUILD_DOCS=ON ..

cmake -DCMAKE_TOOLCHAIN_FILE=/home/dimitri/code/IOHexperimenter/mingw-w64-toolchain.cmake -DCMAKE_INSTALL_PREFIX=./IOHexperimenter_headers ..

sudo make install
```

Build everything:
```sh
cd /home/dimitri/code/IOHexperimenter
sudo rm -rf build
mkdir build
cd build
cmake -DCMAKE_TOOLCHAIN_FILE=/home/dimitri/code/IOHexperimenter/mingw-w64-toolchain.cmake -DCMAKE_INSTALL_PREFIX=./IOHexperimenter_headers ..
sudo make install
```



February 1, 2024
===========================================================================

There is a problem with the Python package. Specifically, it shows that essentially, we write null characters inside the string that's supposed to be the optimization problem names. Apparently, the CEC functions are not loaded properly from C++ into Python. Now, there is also the problem that the CEC functions are not loaded at all, yet these weird signs appear and a function called Levy appears although it's loading code has been removed from problems.cpp. There is also a newer version of the package called ioh-1.14.0. There could be a way to load CEC functions, a way inside the package, that I'm unaware of. Also I get errors when running unit tests on Ubuntu, but there are no errors on 32-bit Windows. Additionally, Windows cannot find the ioh_data.zip file but Ubuntu on GitHub Actions seems to be able to find it.

My judgment is that the package is broken. The package should be fixed properly. The package should run on local Ubuntu first, then verify that one CEC function is properly loaded on GitHub's Ubuntu. Then ensure that all one CEC function is properly loaded on GitHub's Windows. Then add more CEC functions, and test these on local Ubuntu first. Use the most-up-to-date IOH version. Verify that one CEC function is actually loaded as expected.



# More ways to control the output of conda:
```sh
conda config --set notify_outdated_conda false
conda config --set auto_update_conda false
```

Compilers
```
GNU 9.4.0
Microsoft Visual C++

clang++
g++-9
MSVC 19.37.32826.1
```

We get `CMake Deprecation Warning`s for these GitHub repos:
```sh
external/json/CMakeLists.txt
external/pybind11/CMakeLists.txt
```

Run Unit tests:
```sh
python -m unittest -v
```

Now, I need to ensure that the Python get_problem function can be executed in the home folder. Basically, I need that code to manipulate the environment variable. But why do I need that Python code? It only sets the environment variable correctly, once the IOH module has been imported. And then the C++ code actually uses that environment variable. What if we run on GitHub? For this case, we can prefer the GitHub environment variable. In the C++ code. To the IOH_RESOURCES environment variable. Set by Python. Why not call it PYTHON_RESOURCES then? Let's check where the static/ folder actually ends up being.

Then, we will have two environment variables: GITHUB and PYTHON. Essentially, we prefer GITHUB if found, otherwise PYTHON. What if C++ is called without Python? And without GitHub? Let me check. We had this .env file here. But was it compiled? Or loaded during the program's runtime? It definitely wasn't compiled. This would be bad practice anyway. It must have been loaded. Hmm. Probably, actually this file is just loaded from the current directory. Maybe, if we can't find that environment variable. Then look for this file using dotenv or something that climbs up the ladder in search of the file. You know? Then load the whole file. Check the env vars again. Then fail with writing into the log file. I would say, just load the god damn env file yourself. I will just fail if I don't find it. Ok.

So, GITHUB, IOH_RESOURCES. Basically, we use IOH_RESOURCES from both Python and C++. And we use GITHUB because that GitHub does not install the Python package properly. It does not? Also, if it runs C++ tests, then we would assume to have that right? Ah, okay, so in this case, we can fallback? Yes, that's alright. Basically, we start with IOH_RESOURCES. (Just load that yourself, god damn it!) Then, if that's not found, fallback on GITHUB. It's a like an additional trap. Ok, and if that is not found, we fail by writing to log file. Is that good? Perfect.

Thu, 08 February, 11:54:25
========================================

